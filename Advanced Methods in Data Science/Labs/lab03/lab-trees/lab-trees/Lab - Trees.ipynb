{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36333990",
   "metadata": {},
   "source": [
    "# Lab - Decision Trees \n",
    "\n",
    "This lab asks you to play with regression and classification trees,\n",
    "and find the best combination of hyperparameters.  We use Wisconsin\n",
    "Diagnostic Breast Cancer (WDBC) data for categorization and Boston\n",
    "housing data for regression.  Both tasks are fairly similar.\n",
    "\n",
    "The aim of this lab is to give you some experience with trees and\n",
    "hyperparameter tuning.  Try to get as good accuracy/RMSE as possible!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7865efc5",
   "metadata": {},
   "source": [
    "## Classification \n",
    "In this task you work with WDBC data.  As a reminder, your task is to\n",
    "predict __diagnosis__ (''M'' = cancer, ''B'' = no cancer).  \n",
    "\n",
    "\n",
    "1. Load wdbc data and ensure it looks good.\n",
    "\n",
    "\n",
    "2. Create your feature matrix $X$ and label vector $y$.  The former should contain all 30 features,  everything, except __diagnosis__ and __id__.  The latter should be __diagnosis__, converted to either logical or numeric variable (otherwise sklearn will fail).\n",
    "\n",
    "\n",
    "3.  Split your data into training and validation chunks (or do cross validation below, but that is slower).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "fabd5d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code goes here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "06472bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius.mean</th>\n",
       "      <th>texture.mean</th>\n",
       "      <th>perimeter.mean</th>\n",
       "      <th>area.mean</th>\n",
       "      <th>smoothness.mean</th>\n",
       "      <th>compactness.mean</th>\n",
       "      <th>concavity.mean</th>\n",
       "      <th>concpoints.mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius.worst</th>\n",
       "      <th>texture.worst</th>\n",
       "      <th>perimeter.worst</th>\n",
       "      <th>area.worst</th>\n",
       "      <th>smoothness.worst</th>\n",
       "      <th>compactness.worst</th>\n",
       "      <th>concavity.worst</th>\n",
       "      <th>concpoints.worst</th>\n",
       "      <th>symmetry.worst</th>\n",
       "      <th>fracdim.worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius.mean  texture.mean  perimeter.mean  area.mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness.mean  compactness.mean  concavity.mean  concpoints.mean  ...  \\\n",
       "0          0.11840           0.27760          0.3001          0.14710  ...   \n",
       "1          0.08474           0.07864          0.0869          0.07017  ...   \n",
       "2          0.10960           0.15990          0.1974          0.12790  ...   \n",
       "3          0.14250           0.28390          0.2414          0.10520  ...   \n",
       "4          0.10030           0.13280          0.1980          0.10430  ...   \n",
       "\n",
       "   radius.worst  texture.worst  perimeter.worst  area.worst  smoothness.worst  \\\n",
       "0         25.38          17.33           184.60      2019.0            0.1622   \n",
       "1         24.99          23.41           158.80      1956.0            0.1238   \n",
       "2         23.57          25.53           152.50      1709.0            0.1444   \n",
       "3         14.91          26.50            98.87       567.7            0.2098   \n",
       "4         22.54          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness.worst  concavity.worst  concpoints.worst  symmetry.worst  \\\n",
       "0             0.6656           0.7119            0.2654          0.4601   \n",
       "1             0.1866           0.2416            0.1860          0.2750   \n",
       "2             0.4245           0.4504            0.2430          0.3613   \n",
       "3             0.8663           0.6869            0.2575          0.6638   \n",
       "4             0.2050           0.4000            0.1625          0.2364   \n",
       "\n",
       "   fracdim.worst  \n",
       "0        0.11890  \n",
       "1        0.08902  \n",
       "2        0.08758  \n",
       "3        0.17300  \n",
       "4        0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "wdbc = pd.read_csv(\"wdbc.csv.bz2\")\n",
    "wdbc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "41db9463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 32)\n",
      "\n",
      "id                   0\n",
      "diagnosis            0\n",
      "radius.mean          0\n",
      "texture.mean         0\n",
      "perimeter.mean       0\n",
      "area.mean            0\n",
      "smoothness.mean      0\n",
      "compactness.mean     0\n",
      "concavity.mean       0\n",
      "concpoints.mean      0\n",
      "symmetry.mean        0\n",
      "fracdim.mean         0\n",
      "radius.se            0\n",
      "texture.se           0\n",
      "perimeter.se         0\n",
      "area.se              0\n",
      "smoothness.se        0\n",
      "compactness.se       0\n",
      "concavity.se         0\n",
      "concpoints.se        0\n",
      "symmetry.se          0\n",
      "fracdim.se           0\n",
      "radius.worst         0\n",
      "texture.worst        0\n",
      "perimeter.worst      0\n",
      "area.worst           0\n",
      "smoothness.worst     0\n",
      "compactness.worst    0\n",
      "concavity.worst      0\n",
      "concpoints.worst     0\n",
      "symmetry.worst       0\n",
      "fracdim.worst        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "print(wdbc.shape)\n",
    "print()\n",
    "print(wdbc.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "f010f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "features = wdbc.loc[:, ~wdbc.columns.isin(['diagnosis', 'id'])].copy()\n",
    "labels = wdbc.loc[:, wdbc.columns.isin(['diagnosis'])].copy()\n",
    "labels[\"diagnosis\"] = np.where(labels[\"diagnosis\"] == \"M\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f377990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a686ef",
   "metadata": {},
   "source": [
    "Now everything should be ready for a few classification trees.  Your\n",
    "task is to analyze the effect of three hyperparameters of DecisionTreeClassifier:\n",
    "max_depth, min_samples_split and min_samples_leaf.  All these hyperparameters help to avoid\n",
    "overfitting. \n",
    "\n",
    "\n",
    "4. Explain what do these hyperparameters do.\n",
    "\n",
    "\n",
    "5. Fit a decision tree (on training data), and compute accuracy (on validation data).  Use a combination of all three hyperparameters when defining the model.  As a refresher, you can create it along these lines:\n",
    "```\n",
    "m = DecisionTreeClassifier(max_depth=7, min_samples_leaf=..., ...)\n",
    "```  \n",
    "and you can compute accuracy on validation data as\n",
    "```\n",
    "m.score(Xv, yv)\n",
    "```\n",
    "where Xv and yv are your validation/test features $X$ and test labels $y$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "5c076b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code goes here\n",
    "#4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb2bce4",
   "metadata": {},
   "source": [
    "- max_depth: sets the maximum level that a tree can descend during the training process\n",
    "- min_samples: specifies the minimum number of samples required to split nodes \n",
    "- min_samples_leaf: controls the number of examples that a terminal leaf node can have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "dbcab8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "m = DecisionTreeClassifier(max_depth = 7, min_samples_split = 2, min_samples_leaf = 1)\n",
    "_ = m.fit(X_train, y_train)\n",
    "m.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c26ef7",
   "metadata": {},
   "source": [
    "Now it is time to do a more thorough search through hyperparameters by\n",
    "performing 3-D grid search.  \n",
    "\n",
    "6. Write a 3-fold nested loop where the outer loop runs over max depth, next loop runs over min samples split, and the innermost loop runs over min sample leafs.  Use a meaningful set of values for each of these.  For instance, I am using:\n",
    "```\n",
    "depths = range(1,6)\n",
    "splits = [2,5,10,20,50,100]\n",
    "leafs = [1,2,5,10,20,50,100]\n",
    "```\n",
    "You may want to start with a smaller number of combinations to speed\n",
    "up the process though.\n",
    "\n",
    "\n",
    "Inside of the loop, define a decision tree classifier using these\n",
    "parameters, fit it on training data, and compute accuracy on\n",
    "validation data.  Essentially you repeat question 5, just inside of the loop.\n",
    "\n",
    "\n",
    "6. Find the best accuracy and the corresponding hyperparameter combination your loop can detect.  You can just check inside the innermost loop if the current accuracy is better than the previous best accuracy.\n",
    "\n",
    "\n",
    "7. Finally, compare the best accuracy you achieved using trees with a similar accuracy using logistic regression (on validation data).(You may want to increase max_iter.) Which model gives you better accuracy?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "65a35a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956140350877193\n",
      "5 2 2\n"
     ]
    }
   ],
   "source": [
    "#code goes here\n",
    "#6\n",
    "\n",
    "splits = [2, 5, 10, 20, 50, 100]\n",
    "leafs = [1, 2, 5, 10, 20, 50, 100]\n",
    "\n",
    "new_accu = 0\n",
    "curr_accu = 0\n",
    "\n",
    "depth = 0\n",
    "split = 0\n",
    "leaf = 0\n",
    "\n",
    "for i in range (1, 6):\n",
    "    for j in splits:\n",
    "        for k in leafs:\n",
    "            m = DecisionTreeClassifier(max_depth = i, min_samples_split = j, min_samples_leaf = k)\n",
    "            _ = m.fit(X_train, y_train)\n",
    "            new_accu = m.score(X_val, y_val)\n",
    "            if curr_accu < new_accu:\n",
    "                curr_accu = new_accu\n",
    "                depth = i\n",
    "                split = j\n",
    "                leaf = k\n",
    "                \n",
    "print(curr_accu) #best accuracy\n",
    "print(depth, split, leaf) #corresponding hyperparameter combination - depth, split, leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "fc8b20d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "m = LogisticRegression(max_iter = 3000)\n",
    "_ = m.fit(X_train, y_train.values.ravel())\n",
    "m.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14e4482",
   "metadata": {},
   "source": [
    "The best accuracy using trees achieved a slightly better result than that using logistic regression on validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88dde7f",
   "metadata": {},
   "source": [
    "## Regression Trees\n",
    "\n",
    "This task is a very similar task to the previous one, just you should do a regression, not classification model.  So you can copy-paste most of your code, and then modify it a little bit.\n",
    "We use Boston housing data and predict the median value (medv) using all other\n",
    "attributes.  Instead of accuracy, we are now using RMSE, and instead of comparing the result with logistic regression, we compare it with linear regression.\n",
    "\n",
    "1. Load boston data and ensure it looks good.\n",
    "\n",
    "\n",
    "2. Create your feature matrix $X$ and outcome/label vector $y$.  The former should contain all features, exceot medv, and the latter is medv.\n",
    "\n",
    "\n",
    "3. Split your data into training and validation chunks (or do cross validation below, but that is slower).\n",
    "\n",
    "4. Fit a regression tree (on training data), and compute RMSE (on validation data).  Use a combination of the same hyperparameters when defining the model.  \n",
    "  \n",
    "As a refresher, RMSE is defined as\n",
    "$RMSE = \\sqrt{\n",
    "      \\frac{1}{N} \\sum_{i=1}^{n} (\\hat y_{i} - y_{i})^{2}\n",
    "    }$\n",
    "\n",
    "\n",
    "5. Write a similar 3-fold nested loop over these three hyperparameters. Inside of the loop, define a decision tree classifier using these parameters, fit it on training data, and compute RMSE on validation data.  Essentially you repeat question 4, just inside of the loop.\n",
    "\n",
    "\n",
    "6. Find the best accuracy and the corresponding hyperparameter combination your loop can detect.  You can just check inside the innermost loop if the current accuracy is better than the previous best accuracy.\n",
    "\n",
    "7. Finally, compare the best RMSE you achieved using regression trees with a RMSE of linear regression (on validation data). Which model gives you better accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "27407ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "    black  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code goes here \n",
    "#1\n",
    "btsn = pd.read_csv(\"boston.csv.bz2\", sep=\"\\t\")\n",
    "btsn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a57fa800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n",
      "\n",
      "crim       0\n",
      "zn         0\n",
      "indus      0\n",
      "chas       0\n",
      "nox        0\n",
      "rm         0\n",
      "age        0\n",
      "dis        0\n",
      "rad        0\n",
      "tax        0\n",
      "ptratio    0\n",
      "black      0\n",
      "lstat      0\n",
      "medv       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "print(btsn.shape)\n",
    "print()\n",
    "print(btsn.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "1f206c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "features = btsn.loc[:, ~btsn.columns.isin(['medv'])].copy()\n",
    "labels = btsn.loc[:, btsn.columns.isin(['medv'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "e6f72ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "c3f8fc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7191659183051256"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "m = DecisionTreeRegressor(max_depth = 7, min_samples_split = 2, min_samples_leaf = 1)\n",
    "_ = m.fit(X_train, y_train)\n",
    "y_pred = m.predict(X_val)\n",
    "\n",
    "rmse = mean_squared_error(y_val, y_pred, squared = False)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "8a9bbf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4426198143584723\n",
      "4 20 2\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "new_rmse = 1000\n",
    "curr_rmse = 1000\n",
    "\n",
    "depth = 0\n",
    "split = 0\n",
    "leaf = 0\n",
    "\n",
    "for i in range (1, 6):\n",
    "    for j in splits:\n",
    "        for k in leafs:\n",
    "            m = DecisionTreeRegressor(max_depth = i, min_samples_split = j, min_samples_leaf = k)\n",
    "            _ = m.fit(X_train, y_train)\n",
    "            y_pred = m.predict(X_val)\n",
    "            new_rmse = mean_squared_error(y_val, y_pred, squared = False)\n",
    "            if curr_rmse > new_rmse:\n",
    "                curr_rmse = new_rmse\n",
    "                depth = i\n",
    "                split = j\n",
    "                leaf = k\n",
    "                \n",
    "print(curr_rmse) #best RMSE\n",
    "print(depth, split, leaf) #corresponding hyperparameter combination - depth, split, leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "53a4d552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8543646502629447\n",
      "4 20 2\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "new_accu = 0\n",
    "curr_accu = 0\n",
    "\n",
    "depth = 0\n",
    "split = 0\n",
    "leaf = 0\n",
    "\n",
    "for i in range (1, 6):\n",
    "    for j in splits:\n",
    "        for k in leafs:\n",
    "            m = DecisionTreeRegressor(max_depth = i, min_samples_split = j, min_samples_leaf = k)\n",
    "            _ = m.fit(X_train, y_train)\n",
    "            new_accu = m.score(X_val, y_val)\n",
    "            if curr_accu < new_accu:\n",
    "                curr_accu = new_accu\n",
    "                depth = i\n",
    "                split = j\n",
    "                leaf = k\n",
    "                \n",
    "print(curr_accu) #best accuracy\n",
    "print(depth, split, leaf) #corresponding hyperparameter combination - depth, split, leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "c9eca147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.531841117074557"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "m = LinearRegression()\n",
    "_ = m.fit(X_train, y_train)\n",
    "y_pred = m.predict(X_val)\n",
    "rmse = mean_squared_error(y_val, y_pred, squared = False)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8aabfa",
   "metadata": {},
   "source": [
    "The best RMSE using regression trees achieved a better result than RMSE using linear regression on validation data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
